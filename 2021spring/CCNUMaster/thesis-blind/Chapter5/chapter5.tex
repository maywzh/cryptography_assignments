\chapter{Conclusion and Future Work}
%在本文中，设计了一个基于图神经网络、Attention-based Bi-LSTM、Transformer以及协同过滤等算法的习题推荐系统。该系统分为三个模块，分别为习题知识点挖掘模块、知识追踪模块和习题推荐模块。习题知识点挖掘模块可以未标注知识点的习题进行知识点标注，并将标注知识点的习题作为知识追踪的输入数据。知识追踪模块追踪学生的做题记录，从而跟踪学生的知识状态。习题推荐模块则结合学生的知识状态和习题标签信息，进行针对性的习题推荐。
\section{Conclusion}
%在未来的工作中，可以结合其他的图神经网络模型或者加入一些记忆力机制来解决模型的序列性问题。
In this thesis, an exercise recommendation system based on knowledge tracing and graph neural network is proposed. The system consists of three modules: the exercise knowledge point tagging module, knowledge tracing module, and exercise recommendation module. The exercise knowledge point tagging module can label the exercises' knowledge points. The marked exercises are adopted as the input data for knowledge tracing and recommendation. The knowledge tracing module tracks the students' question records, thereby tracking the students' knowledge status. The exercise recommendation module combines students' knowledge status and exercise label information to perform exercise recommendations.

%在知识点标注模块中，采用了图卷积神经网络来训练标签标注分类器。通过Bi-LSTM来挖掘习题文本信息，将习题文本嵌入作为标签分类器组的输入，输出一组标签的分类结果。经过实验验证，该模型对于高中数学习题具有良好的分类效果，对于现有的模型性能上有一定提升。在未来的工作中，可以考虑用Transformer来取代Bi-LSTM模型或者用BERT来训练习题文本嵌入来达到更精确的分类效果。

In the knowledge point labeling module, a graph convolutional neural network is trained for encoding the relation among knowledge labels and generate labeling classifiers. Bi-LSTM is applied to encode the exercise text information to transform the exercise text to text representation vector as the label classifier group's input. The classifier finally output a set of label classification results. Experiments show that the model has better classification performance for high school math exercise problems than existing baseline models.

%在知识追踪模块中，提出了一种对于DKVMN模型的改进知识追踪模型，该模型将DKVMN的存储结构用图网络结构改造，从而可以表征存储器中的存储单元之间的相关性。另外，模型引入了用户的答题特征作为知识追踪的额外输入，从而为模型增加了更加广泛的表征能力。在实验阶段，通过对于数据集数据进行预处理和数据分析，选取出与输出特征最为相关的行为特征作为输入。在与基线模型的对比试验中，提出的模型取得了最佳的性能。
In the knowledge tracing module, an improved model for the DKVMN is proposed, which transforms the memory structure of DKVMN with a graph network structure so that the correlations among the memory slots can be represented. Besides, the model introduces the user's answering behavior features as additional inputs for knowledge tracing, thus enhancing representing capability to the model. In the experimental phase, the behavioral features that are most relevant to the output features are selected as inputs by performing data analysis for the dataset data. In comparison with the baseline model, the proposed model achieves the best performance.


%在习题推荐模块中，提出一个基于Matching-Ranking双阶段的数学习题推荐模型。其中第一阶段的Matching模型为一个多路习题推荐项匹配模型，该模型采用了基于协同过滤、热门度、用户偏好等多个子召回策略用于分别生成习题推荐候选集合，然后在融合阶段将这些候选集合进行加权融合，形成一个最终的融合习题推荐候选集合。在排序阶段，将Matching阶段获取的习题候选集合中的每个习题输入到知识追踪习题进行正确率预测，将最容易出错的习题的作为优先级最高的推荐项，按照此策略生成推荐习题集。

In the exercise recommendation module, a two-stage Matching-Ranking based mathematical exercise recommendation model is proposed. The Matching model in the first stage is a multiplexed exercise recommendation item matching model, which applied multiple sub-matching strategies based on collaborative filtering, popularity, user preferences for generating exercise recommendation candidate sets separately, and then these candidate sets are weighted and fused in the fusion stage to form a final fused exercise recommendation candidate set. In the ranking phase, each exercise in the set of exercise candidates obtained in the Matching phase is input to the knowledge tracing exercise for correctness prediction, and the most error-prone exercises are used as the recommendation item with the highest priority. The recommended set of exercises is generated according to this strategy.

%在未来的工作中，对于习题知识点标注模型，可以应用目前较为热门的预训练模型例如BERT,GPT等来进行嵌入学习和命名试题挖掘等工作，这样可以对于习题文本进行更深层次的语义理解，取得更好的效果。对于知识追踪模型，可以考虑应用其他图神经网络模型进行习题-知识点图嵌入学习，将知识点的关系定量化来建模，另外可以设计显式知识点掌握度矩阵来可视化学生对于具体知识点的掌握情况。对于习题推荐模型，可以应用神经网络模型来自适应调整各个召回策略的超参数，降低人工调参成本。

\section{Future Work}

There are still some shortcomings in this study, and the proposed method and model can be improved in the future work.

For the exercise knowledge labeling model, the popular pre-trained models (such as BERT, GPT) which can provide a deeper semantic understanding of the exercise text can be applied for word embedding or the text classification. Alternatively, a hierarchical labeling model can be introduced to solve the hierarchical label classification problem.

For the knowledge tracing model, the Multi-head attention mechanism can be applied to the knowledge point relation representation to generate trainable adjacency relation, which improves model flexibility. Also, more feature information can be introduced to enhance the higher-order feature characterization capability of the model.

For the exercise recommendation model, neural network models can adaptively adjust each matching strategy's hyperparameters to reduce manual tuning costs. The recommendation ranking model can add more features to enhance the comprehensiveness of the model recommendations.