\chapter{Conclusion and Future Work}
%在本文中，设计了一个基于图神经网络、Attention-based Bi-LSTM、Transformer以及协同过滤等算法的习题推荐系统。该系统分为三个模块，分别为习题知识点挖掘模块、知识追踪模块和习题推荐模块。习题知识点挖掘模块可以未标注知识点的习题进行知识点标注，并将标注知识点的习题作为知识追踪的输入数据。知识追踪模块追踪学生的做题记录，从而跟踪学生的知识状态。习题推荐模块则结合学生的知识状态和习题标签信息，进行针对性的习题推荐。

%在未来的工作中，可以结合其他的图神经网络模型或者加入一些记忆力机制来解决模型的序列性问题。
In this thesis, an exercise recommendation system based on knowledge tracing is designed. The system is divided into three modules: the exercise knowledge point tagging module, knowledge tracking module, and exercise recommendation module. The exercise knowledge point tagging module can mark the exercises' knowledge points without the knowledge points and use the marked knowledge points as the input data for knowledge tracking. The knowledge tracking module tracks the students' question records, thereby tracking the students' knowledge status. The exercise recommendation module combines students' knowledge status and exercise label information to make targeted exercise recommendations.

%在知识点标注模块中，采用了图卷积神经网络来训练标签标注分类器。通过Bi-LSTM来挖掘习题文本信息，将习题文本嵌入作为标签分类器组的输入，输出一组标签的分类结果。经过实验验证，该模型对于高中数学习题具有良好的分类效果，对于现有的模型性能上有一定提升。在未来的工作中，可以考虑用Transformer来取代Bi-LSTM模型或者用BERT来训练习题文本嵌入来达到更精确的分类效果。

In the knowledge point annotation module, a graph convolutional neural network is used to train the label annotation classifier. Use Bi-LSTM to mine the exercise text information, embed the exercise text as the label classifier group's input, and output a set of label classification results. Experiments show that the model has a good classification effect for high school math learning problems and has a specific improvement in existing models' performance. In future work, a Transformer can be applied to replace the Bi-LSTM model or BERT to train exercise text embedding to achieve more accurate classification results.

%在知识追踪模块中，采用了图注意力网络来进行习题知识关系嵌入学习，将嵌入向量通过基于Transformer的Encoder模型来输出一个知识状态向量，再将习题嵌入向量与知识状态向量作为基于Transformer的Decoder模型的输入，输出对于下一道习题的答题情况预测。经过实验验证，该模型对于知识关系简单与知识关系复杂的数据集都具有较好的预测性能。后续可以考虑采用不同的图神经网络模型来增加学习效率，或者采用更多的习题信息来学习习题知识嵌入。

In the knowledge tracking module, a graph attention network is used to learn exercises' knowledge relationships. The embedding vector is output through the Transformer-based Encoder model to output a knowledge state vector, and then the exercise embedding vector and the knowledge state vector are used as the Transformer-based Decoder. The input and output of the model predict the answer to the next exercise. After experimental verification, the model has good predictive performance for data sets with complex and straightforward knowledge relationships. Later, consider using different graph neural network models as an optional method to increase learning efficiency or use more exercise information to learn exercise knowledge embedding.

%在习题推荐模块中，提出一个基于Matching-Ranking双阶段的数学习题推荐模型。其中第一阶段的Matching模型为一个多路习题推荐项匹配模型，该模型采用了基于协同过滤、热门度、用户偏好等多个子召回策略用于分别生成习题推荐候选集合，然后在融合阶段将这些候选集合进行加权融合，形成一个最终的融合习题推荐候选集合。在排序阶段，将Matching阶段获取的习题候选集合中的每个习题输入到知识追踪习题进行正确率预测，将最容易出错的习题的作为优先级最高的推荐项，按照此策略生成推荐习题集。

In the exercise recommendation module, a two-stage Matching-Ranking based mathematical exercise recommendation model is proposed. The Matching model in the first stage is a multiplexed exercise recommendation item matching model, which employs multiple sub-matching strategies based on collaborative filtering, popularity, user preferences for generating exercise recommendation candidate sets separately, and then these candidate sets are weighted and fused in the fusion stage to form a final fused exercise recommendation candidate set. In the ranking phase, each exercise in the set of exercise candidates obtained in the Matching phase is input to the knowledge tracking exercise for correctness prediction, and the most error-prone exercises are used as the recommendation item with the highest priority, and the recommended set of exercises is generated according to this strategy.

%在未来的工作中，对于习题知识点标注模型，可以应用目前较为热门的预训练模型例如BERT,GPT等来进行嵌入学习和命名试题挖掘等工作，这样可以对于习题文本进行更深层次的语义理解，取得更好的效果。对于知识追踪模型，可以考虑应用其他图神经网络模型进行习题-知识点图嵌入学习，将知识点的关系定量化来建模，另外可以设计显式知识点掌握度矩阵来可视化学生对于具体知识点的掌握情况。对于习题推荐模型，可以应用神经网络模型来自适应调整各个召回策略的超参数，降低人工调参成本。

In future work, for the exercise knowledge point labeling model, the popular pre-training models such as BERT, GPT can be applied for embedding learning and named test mining, which can provide a deeper semantic understanding of the exercise text and achieve better results. For the knowledge tracking model, applying other graphical neural network models can be an option to embed the learning of exercise - knowledge point graphs to quantify the relationship of knowledge points to the model. An explicit knowledge mastery matrix can be designed to visualize students' mastery of specific knowledge points. For the exercise recommendation model, neural network models can adaptively adjust each matching strategy's hyperparameters to reduce manual tuning costs.