\chapter{Conclusion and Future Work}
%在本文中，设计了一个基于图神经网络、Attention-based Bi-LSTM、Transformer以及协同过滤等算法的习题推荐系统。该系统分为三个模块，分别为习题知识点挖掘模块、知识追踪模块和习题推荐模块。习题知识点挖掘模块可以未标注知识点的习题进行知识点标注，并将标注知识点的习题作为知识追踪的输入数据。知识追踪模块追踪学生的做题记录，从而跟踪学生的知识状态。习题推荐模块则结合学生的知识状态和习题标签信息，进行针对性的习题推荐。
\section{Conclusion}
%在未来的工作中，可以结合其他的图神经网络模型或者加入一些记忆力机制来解决模型的序列性问题。
In this thesis, an exercise recommendation system based on knowledge tracing is designed. The system is divided into three modules: the exercise knowledge point tagging module, knowledge tracing module, and exercise recommendation module. The exercise knowledge point tagging module can mark the exercises' knowledge points without the knowledge points and use the marked knowledge points as the input data for knowledge tracing. The knowledge tracing module tracks the students' question records, thereby tracking the students' knowledge status. The exercise recommendation module combines students' knowledge status and exercise label information to make targeted exercise recommendations.

%在知识点标注模块中，采用了图卷积神经网络来训练标签标注分类器。通过Bi-LSTM来挖掘习题文本信息，将习题文本嵌入作为标签分类器组的输入，输出一组标签的分类结果。经过实验验证，该模型对于高中数学习题具有良好的分类效果，对于现有的模型性能上有一定提升。在未来的工作中，可以考虑用Transformer来取代Bi-LSTM模型或者用BERT来训练习题文本嵌入来达到更精确的分类效果。

In the knowledge point annotation module, a graph convolutional neural network is used to train the label annotation classifier. Use Bi-LSTM to mine the exercise text information, embed the exercise text as the label classifier group's input, and output a set of label classification results. Experiments show that the model has a good classification effect for high school math learning problems and has a specific improvement in existing models' performance. In future work, a Transformer can be applied to replace the Bi-LSTM model or BERT to train exercise text embedding to achieve more accurate classification results.

%在知识追踪模块中，提出了一种对于DKVMN模型的改进知识追踪模型，该模型将DKVMN的存储结构用图网络结构改造，从而可以表征存储器中的存储单元之间的相关性。另外，模型引入了用户的答题特征作为知识追踪的额外输入，从而为模型增加了更加广泛的表征能力。在实验阶段，通过对于数据集数据进行预处理和数据分析，选取出与输出特征最为相关的行为特征作为输入。在与基线模型的对比试验中，提出的模型取得了最佳的性能。
In the knowledge tracing module, an improved model for the DKVMN is proposed, which transforms the storage structure of DKVMN with a graph network structure so that the correlations among the storage units in the memory can be characterized. In addition, the model introduces the user's answer features as additional inputs for knowledge tracing, thus adding a broader characterization capability to the model. In the experimental phase, the behavioral features that are most relevant to the output features are selected as inputs by pre-processing and data analysis for the dataset data. In comparison tests with the baseline model, the proposed model achieves the best performance.


%在习题推荐模块中，提出一个基于Matching-Ranking双阶段的数学习题推荐模型。其中第一阶段的Matching模型为一个多路习题推荐项匹配模型，该模型采用了基于协同过滤、热门度、用户偏好等多个子召回策略用于分别生成习题推荐候选集合，然后在融合阶段将这些候选集合进行加权融合，形成一个最终的融合习题推荐候选集合。在排序阶段，将Matching阶段获取的习题候选集合中的每个习题输入到知识追踪习题进行正确率预测，将最容易出错的习题的作为优先级最高的推荐项，按照此策略生成推荐习题集。

In the exercise recommendation module, a two-stage Matching-Ranking based mathematical exercise recommendation model is proposed. The Matching model in the first stage is a multiplexed exercise recommendation item matching model, which employs multiple sub-matching strategies based on collaborative filtering, popularity, user preferences for generating exercise recommendation candidate sets separately, and then these candidate sets are weighted and fused in the fusion stage to form a final fused exercise recommendation candidate set. In the ranking phase, each exercise in the set of exercise candidates obtained in the Matching phase is input to the knowledge tracing exercise for correctness prediction, and the most error-prone exercises are used as the recommendation item with the highest priority. The recommended set of exercises is generated according to this strategy.

%在未来的工作中，对于习题知识点标注模型，可以应用目前较为热门的预训练模型例如BERT,GPT等来进行嵌入学习和命名试题挖掘等工作，这样可以对于习题文本进行更深层次的语义理解，取得更好的效果。对于知识追踪模型，可以考虑应用其他图神经网络模型进行习题-知识点图嵌入学习，将知识点的关系定量化来建模，另外可以设计显式知识点掌握度矩阵来可视化学生对于具体知识点的掌握情况。对于习题推荐模型，可以应用神经网络模型来自适应调整各个召回策略的超参数，降低人工调参成本。

\section{Future Work}
In future work, for the exercise knowledge point labeling model, the popular pre-training models such as BERT, GPT can be applied for embedding learning and named test mining, which can provide a deeper semantic understanding of the exercise text and achieve better results. For the knowledge tracing model, applying other graphical neural network models can be an option to embed the learning of exercise-knowledge point graphs to quantify the relationship of knowledge points to the model. An explicit knowledge mastery matrix can be designed to visualize students' mastery of specific knowledge points. Furthermore, the Multi-head attention mechanism can be applied to the knowledge point relation representation to generate trainable adjacency relation. For the exercise recommendation model, neural network models can adaptively adjust each matching strategy's hyperparameters to reduce manual tuning costs.