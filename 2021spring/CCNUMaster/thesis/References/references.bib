@article{Wu_2021,
  author    = {Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Yu, Philip S.},
  doi       = {10.1109/tnnls.2020.2978386},
  issn      = {2162-2388},
  journal   = {IEEE Transactions on Neural Networks and Learning Systems},
  month     = {Jan},
  number    = {1},
  pages     = {4-24},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  title     = {A Comprehensive Survey on Graph Neural Networks},
  url       = {http://dx.doi.org/10.1109/TNNLS.2020.2978386},
  volume    = {32},
  year      = {2021}
}

@inproceedings{choi2021appropriate,
  author    = {Choi, Youngduck and Lee, Youngnam and Cho, Junghyun and Baek, Jineon and Kim, Byungsoo and Cha, Yeongmin and Shin, Dongmin and Bae, Chan and Heo, Jaewe},
  booktitle = {{arXiv}:2002.07033 [cs]},
  doi       = {10.1145/3448139.3448188},
  keywords  = {Computer Science - Artificial Intelligence, Computer Science - Computers and Society, Computer Science - Machine Learning, ⚠️ Invalid DOI},
  language  = {en},
  month     = jan,
  note      = {arXiv: 2002.07033},
  title     = {Towards an {Appropriate} {Query}, {Key}, and {Value} {Computation} for {Knowledge} {Tracing}},
  url       = {http://arxiv.org/abs/2002.07033},
  urldate   = {2021-02-21},
  year      = {2021}
}

@article{wu2020comprehensive,
  author    = {Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Philip, S Yu},
  journal   = {IEEE transactions on neural networks and learning systems},
  publisher = {IEEE},
  title     = {A comprehensive survey on graph neural networks},
  year      = {2020}
}

@article{wu2020comprehensive,
  author    = {Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Philip, S Yu},
  journal   = {IEEE transactions on neural networks and learning systems},
  publisher = {IEEE},
  title     = {A comprehensive survey on graph neural networks},
  year      = {2020}
}

@inproceedings{lindemann2020survey,
  title     = {A Survey on Long Short-Term Memory Networks for Time Series Prediction},
  author    = {Lindemann, Benjamin and M{\"u}ller, Timo and Vietz, Hannes and Jazdi, Nasser and Weyrich, Michael},
  booktitle = {2020 14th CIRP Conference on Intelligent Computation in Manufacturing Engineering (ICME), Gulf of Naples},
  year      = {2020}
}

@misc{chaudhari2020attentive,
  title         = {An Attentive Survey of Attention Models},
  author        = {Sneha Chaudhari and Varun Mithal and Gungor Polatkan and Rohan Ramanath},
  year          = {2020},
  eprint        = {1904.02874},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@article{jang2020bi,
  title     = {Bi-LSTM model to increase accuracy in text classification: combining Word2vec CNN and attention mechanism},
  author    = {Jang, Beakcheol and Kim, Myeonghwi and Harerimana, Gaspard and Kang, Sang-ug and Kim, Jong Wook},
  journal   = {Applied Sciences},
  volume    = {10},
  number    = {17},
  pages     = {5841},
  year      = {2020},
  publisher = {Multidisciplinary Digital Publishing Institute}
}

@article{cogsim2020,
  author         = {Nguyen, Luong Vuong and Hong, Min-Sung and Jung, Jason J. and Sohn, Bong-Soo},
  title          = {Cognitive Similarity-Based Collaborative Filtering Recommendation System},
  journal        = {Applied Sciences},
  volume         = {10},
  year           = {2020},
  number         = {12},
  article-number = {4183},
  url            = {https://www.mdpi.com/2076-3417/10/12/4183},
  issn           = {2076-3417},
  abstract       = {This paper provides a new approach that improves collaborative filtering results in recommendation systems. In particular, we aim to ensure the reliability of the data set collected which is to collect the cognition about the item similarity from the users. Hence, in this work, we collect the cognitive similarity of the user about similar movies. Besides, we introduce a three-layered architecture that consists of the network between the items (item layer), the network between the cognitive similarity of users (cognition layer) and the network between users occurring in their cognitive similarity (user layer). For instance, the similarity in the cognitive network can be extracted from a similarity measure on the item network. In order to evaluate our method, we conducted experiments in the movie domain. In addition, for better performance evaluation, we use the F-measure that is a combination of two criteria     P r e c i s i o n     and     R e c a l l    . Compared with the Pearson Correlation, our method more accurate and achieves improvement over the baseline 11.1% in the best case. The result shows that our method achieved consistent improvement of 1.8% to 3.2% for various neighborhood sizes in MAE calculation, and from 2.0% to 4.1% in RMSE calculation. This indicates that our method improves recommendation performance.},
  doi            = {10.3390/app10124183}
}

@article{zhang2020deep,
  author    = {Zhang, Ziwei and Cui, Peng and Zhu, Wenwu},
  journal   = {IEEE Transactions on Knowledge and Data Engineering},
  publisher = {IEEE},
  title     = {Deep learning on graphs: A survey},
  year      = {2020}
}

@misc{choi2020ednet,
  archiveprefix = {arXiv},
  author        = {Youngduck Choi and Youngnam Lee and Dongmin Shin and Junghyun Cho and Seoyon Park and Seewoo Lee and Jineon Baek and Chan Bae and Byungsoo Kim and Jaewe Heo},
  eprint        = {1912.03072},
  primaryclass  = {cs.CY},
  title         = {EdNet: A Large-Scale Hierarchical Dataset in Education},
  year          = {2020}
}

@article{yang2020gikt,
  author     = {Yang, Yang and Shen, Jian and Qu, Yanru and Liu, Yunfei and Wang, Kerong and Zhu, Yaoming and Zhang, Weinan and Yu, Yong},
  journal    = {arXiv:2009.05991 [cs]},
  language   = {en},
  month      = sep,
  note       = {arXiv: 2009.05991},
  shorttitle = {{GIKT}},
  title      = {{GIKT}: {A} {Graph}-based {Interaction} {Model} for {Knowledge} {Tracing}},
  url        = {http://arxiv.org/abs/2009.05991},
  urldate    = {2021-02-21},
  year       = {2020}
}


% extra
@inproceedings{wang2020neural,
  title     = {Neural cognitive diagnosis for intelligent education systems},
  author    = {Wang, Fei and Liu, Qi and Chen, Enhong and Huang, Zhenya and Chen, Yuying and Yin, Yu and Huang, Zai and Wang, Shijin},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume    = {34},
  pages     = {6153--6161},
  year      = {2020}
}

@inproceedings{cui2019pre,
  title     = {Revisiting Pre-Trained Models for {C}hinese Natural Language Processing},
  author    = {Cui, Yiming  and
      Che, Wanxiang  and
      Liu, Ting  and
      Qin, Bing  and
      Wang, Shijin  and
      Hu, Guoping},
  booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings},
  month     = nov,
  year      = {2020},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://www.aclweb.org/anthology/2020.findings-emnlp.58},
  pages     = {657--668}
}

@misc{liu2020emerging,
  archiveprefix = {arXiv},
  author        = {Weiwei Liu and Xiaobo Shen and Haobo Wang and Ivor W. Tsang},
  eprint        = {2011.11197},
  primaryclass  = {cs.LG},
  title         = {The Emerging Trends of Multi-Label Learning},
  year          = {2020}
}

@article{vinuesa2020role,
  author    = {Vinuesa, Ricardo and Azizpour, Hossein and Leite, Iolanda and Balaam, Madeline and Dignum, Virginia and Domisch, Sami and Fell{\"a}nder, Anna and Langhans, Simone Daniela and Tegmark, Max and Nerini, Francesco Fuso},
  journal   = {Nature communications},
  number    = {1},
  pages     = {1--10},
  publisher = {Nature Publishing Group},
  title     = {The role of artificial intelligence in achieving the Sustainable Development Goals},
  volume    = {11},
  year      = {2020}
}

@article{huang2020utilizing,
  title     = {Utilizing response times in cognitive diagnostic computerized adaptive testing under the higher-order deterministic input, noisy ‘and’gate model},
  author    = {Huang, Hung-Yu},
  journal   = {British Journal of Mathematical and Statistical Psychology},
  volume    = {73},
  number    = {1},
  pages     = {109--141},
  year      = {2020},
  publisher = {Wiley Online Library}
}

@inproceedings{sakt2019,
  title     = {A self-attentive model for knowledge tracing},
  author    = {Shalini Pandey and George Karypis},
  year      = {2019},
  series    = {EDM 2019 - Proceedings of the 12th International Conference on Educational Data Mining},
  publisher = {International Educational Data Mining Society},
  pages     = {384--389}
}

@misc{pandey2019selfattentive,
  archiveprefix = {arXiv},
  author        = {Shalini Pandey and George Karypis},
  eprint        = {1907.06837},
  primaryclass  = {cs.LG},
  title         = {A Self-Attentive model for Knowledge Tracing},
  year          = {2019}
}
@article{kldsim2019,
  author   = {Jiangzhou Deng and Yong Wang and Junpeng Guo and Yongheng Deng and Jerry Gao and Younghee Park},
  title    = {A similarity measure based on Kullback-Leibler divergence for collaborative filtering in sparse data},
  journal  = {Journal of Information Science},
  volume   = {45},
  number   = {5},
  pages    = {656-675},
  year     = {2019},
  doi      = {10.1177/0165551518808188},
  url      = { 
        https://doi.org/10.1177/0165551518808188
    
},
  eprint   = { 
        https://doi.org/10.1177/0165551518808188
    
},
  abstract = { In the neighbourhood-based collaborative filtering (CF) algorithms, a user similarity measure is used to find other users similar to an active user. Most of the existing user similarity measures rely on the co-rated items. However, there are not enough co-rated items in sparse dataset, which usually leads to poor prediction. In this article, a new similarity scheme is proposed, which breaks free of the constraint of the co-rated items. Moreover, an item similarity measure based on the Kullback–Leibler (KL) divergence is presented, which identifies the relation between items based on the probability density distribution of ratings. Since the item similarity based on KL divergence makes full use of all ratings, it owns better flexibility for sparse datasets. The CF algorithm using our proposed similarity scheme is implemented and compared with some classic CF algorithms. The compared results show that the CF using our similarity has better predictive performance. Therefore, our similarity scheme is a good solution for the sparsity problem and has great potential to be applied to recommendation systems. }
}

@article{soltani2019adaptive,
  author    = {Soltani, Alireza and Izquierdo, Alicia},
  journal   = {Nature Reviews Neuroscience},
  number    = {10},
  pages     = {635--644},
  publisher = {Nature Publishing Group},
  title     = {Adaptive learning under expected and unexpected uncertainty},
  volume    = {20},
  year      = {2019}
}

@inproceedings{hu2019introductory,
  author       = {Hu, Dichao},
  booktitle    = {Proceedings of SAI Intelligent Systems Conference},
  organization = {Springer},
  pages        = {432--448},
  title        = {An introductory survey on attention mechanisms in NLP problems},
  year         = {2019}
}


@misc{devlin2019bert,
  archiveprefix = {arXiv},
  author        = {Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
  eprint        = {1810.04805},
  primaryclass  = {cs.CL},
  title         = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  year          = {2019}
}


@article{liu2019bidirectional,
  title     = {Bidirectional LSTM with attention mechanism and convolutional layer for text classification},
  author    = {Liu, Gang and Guo, Jiabao},
  journal   = {Neurocomputing},
  volume    = {337},
  pages     = {325--338},
  year      = {2019},
  publisher = {Elsevier}
}

@article{fu2019collaborative,
  title     = {Collaborative filtering recommendation algorithm towards intelligent community},
  author    = {Fu, Wei and Liu, Jun and Lai, Yirong},
  journal   = {Discrete \& Continuous Dynamical Systems-S},
  volume    = {12},
  number    = {4\&5},
  pages     = {811},
  year      = {2019},
  publisher = {American Institute of Mathematical Sciences}
}


@article{Lee2019CreatingAN,
  title   = {Creating A Neural Pedagogical Agent by Jointly Learning to Review and Assess},
  author  = {Y. Lee and Youngduck Choi and Jung-hyun Cho and Alexander R. Fabbri and Hyunbin Loh and Chanyou Hwang and Yongku Lee and Sang-Wook Kim and Dragomir R. Radev},
  journal = {ArXiv},
  year    = {2019},
  volume  = {abs/1906.10910}
}

@article{guo2019deep,
  author    = {Guo, Wenzhong and Wang, Jianwen and Wang, Shiping},
  journal   = {IEEE Access},
  pages     = {63373--63394},
  publisher = {IEEE},
  title     = {Deep multimodal representation learning: A survey},
  volume    = {7},
  year      = {2019}
}


@inproceedings{kim2019edge,
  title     = {Edge-labeling graph neural network for few-shot learning},
  author    = {Kim, Jongmin and Kim, Taesup and Kim, Sungwoong and Yoo, Chang D},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages     = {11--20},
  year      = {2019}
}


@inproceedings{huang2019exploring,
  title     = {Exploring multi-objective exercise recommendations in online education systems},
  author    = {Huang, Zhenya and Liu, Qi and Zhai, Chengxiang and Yin, Yu and Chen, Enhong and Gao, Weibo and Hu, Guoping},
  booktitle = {Proceedings of the 28th ACM International Conference on Information and Knowledge Management},
  pages     = {1261--1270},
  year      = {2019}
}


@inproceedings{nakagawa2019graph,
  author       = {Nakagawa, Hiromi and Iwasawa, Yusuke and Matsuo, Yutaka},
  booktitle    = {2019 IEEE/WIC/ACM International Conference on Web Intelligence (WI)},
  organization = {IEEE},
  pages        = {156--163},
  title        = {Graph-based knowledge tracing: modeling student proficiency using graph neural network},
  year         = {2019}
}



@inproceedings{panjaitan2019implementation,
  title        = {Implementation of Apriori Algorithm for Analysis of Consumer Purchase Patterns},
  author       = {Panjaitan, Suprianto and Amin, Muhammad and Lindawati, Sri and Watrianthos, Ronal and Sihotang, Hengki Tamando and Sinaga, Bosker and others},
  booktitle    = {Journal of Physics: Conference Series},
  volume       = {1255},
  number       = {1},
  pages        = {012057},
  year         = {2019},
  organization = {IOP Publishing}
}

@article{guo2019improving,
  title     = {Improving text classification with weighted word embeddings via a multi-channel TextCNN model},
  author    = {Guo, Bao and Zhang, Chunxia and Liu, Junmin and Ma, Xiaoyi},
  journal   = {Neurocomputing},
  volume    = {363},
  pages     = {366--374},
  year      = {2019},
  publisher = {Elsevier}
}

@article{pliakos_integrating_2019,
  title    = {Integrating machine learning into item response theory for addressing the cold start problem in adaptive learning systems},
  volume   = {137},
  issn     = {0360-1315},
  url      = {https://www.sciencedirect.com/science/article/pii/S036013151930096X},
  doi      = {10.1016/j.compedu.2019.04.009},
  abstract = {Adaptive learning systems aim to provide learning items tailored to the behavior and needs of individual learners. However, one of the outstanding challenges in adaptive item selection is that often the corresponding systems do not have information on initial ability levels of new learners entering a learning environment. Thus, the proficiency of those new learners is very difficult to be predicted. This heavily impairs the quality of personalized items' recommendation during the initial phase of the learning environment. In order to handle this issue, known as the cold-start problem, we propose a system that combines item response theory (IRT) with machine learning. Specifically, we perform ability estimation and item response prediction for new learners by integrating IRT with classification and regression trees built on learners’ side information. The goal of this work is to build a learning system that incorporates IRT and machine learning into a unified framework. We compare the proposed hybrid model to alternative approaches by conducting experiments on two educational data sets. The obtained results affirmed the potential of the proposed method. In particular, the obtained results indicate that IRT combined with Random Forests provides the lowest error for the ability estimation and the highest accuracy in terms of response prediction. This way, we deduce that the employment of machine learning in combination with IRT could indeed alleviate the effect of the cold start problem in an adaptive learning environment.},
  journal  = {Computers \& Education},
  author   = {Pliakos, Konstantinos and Joo, Seang-Hwane and Park, Jung Yeon and Cornillie, Frederik and Vens, Celine and Noortgate, Wim Van den},
  year     = {2019},
  keywords = {Adaptive learning system, Cold-start problem, Decision tree learning, Item response theory, Machine learning},
  pages    = {91--103},
  file     = {2019_Pliakos et al_Integrating machine learning into item response theory for addressing the cold.pdf:/Users/maywzh/OneDrive/Documents/Literature/2019_Pliakos et al_Integrating machine learning into item response theory for addressing the cold.pdf:application/pdf}
}

@article{Abdelrahman_2019,
  author    = {Abdelrahman, Ghodai and Wang, Qing},
  doi       = {10.1145/3331184.3331195},
  isbn      = {9781450361729},
  journal   = {Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval},
  month     = {Jul},
  publisher = {ACM},
  title     = {Knowledge Tracing with Sequential Key-Value Memory Networks},
  url       = {http://dx.doi.org/10.1145/3331184.3331195},
  year      = {2019}
}

@inproceedings{chen2019multi,
  author    = {Chen, Zhao-Min and Wei, Xiu-Shen and Wang, Peng and Guo, Yanwen},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages     = {5177--5186},
  title     = {Multi-label image recognition with graph convolutional networks},
  year      = {2019}
}

@inproceedings{kampffmeyer2019rethinking,
  author    = {Kampffmeyer, Michael and Chen, Yinbo and Liang, Xiaodan and Wang, Hao and Zhang, Yujia and Xing, Eric P},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages     = {11487--11496},
  title     = {Rethinking knowledge graph propagation for zero-shot learning},
  year      = {2019}
}

@article{Juan_2019,
  doi       = {10.1088/1742-6596/1314/1/012078},
  url       = {https://doi.org/10.1088/1742-6596/1314/1/012078},
  year      = 2019,
  month     = {oct},
  publisher = {{IOP} Publishing},
  volume    = {1314},
  pages     = {012078},
  author    = {Wang Juan and Lan Yue-xin and Wu Chun-ying},
  title     = {Survey of Recommendation Based on Collaborative Filtering},
  journal   = {Journal of Physics: Conference Series},
  abstract  = {This paper introduces the domestic and international research of collaborative filtering, and discusses the main problems of collaborative filtering algorithm, including data sparsity, cold start and accuracy of similarity measure.Then, future research and development trends of integrating deep learning to recommender systems are pointed out. In order to solve the data sparsity and cold start problems in the personalized recommendation system, a hybrid collaborative filtering recommendation algorithm is proposed, which combines the KNN model and XGBoost model. When deep learning is applied to recommendation system by integrating massive multi-sources heterogeneous data,it could improve the performance of the recommendation system.}
}

@article{yang2019knowledgerelation,
  author  = {杨东明 and 杨大为 and 顾航 and 洪道诚 and 高明 and 王晔 and others},
  journal = {华东师范大学学报 (自然科学版)},
  pages   = {53--65},
  title   = {面向初等数学的知识点关系提取研究},
  volume  = {5},
  year    = {2019}
}

@article{chiu2018cognitive,
  title     = {Cognitive diagnosis for small educational programs: The general nonparametric classification method},
  author    = {Chiu, Chia-Yi and Sun, Yan and Bian, Yanhong},
  journal   = {psychometrika},
  volume    = {83},
  number    = {2},
  pages     = {355--375},
  year      = {2018},
  publisher = {Springer}
}


@inproceedings{dettmers2018convolutional,
  author    = {Dettmers, Tim and Minervini, Pasquale and Stenetorp, Pontus and Riedel, Sebastian},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  number    = {1},
  title     = {Convolutional 2d knowledge graph embeddings},
  volume    = {32},
  year      = {2018}
}

@inproceedings{su2018exercise,
  author    = {Su, Yu and Liu, Qingwen and Liu, Qi and Huang, Zhenya and Yin, Yu and Chen, Enhong and Ding, Chris and Wei, Si and Hu, Guoping},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  number    = {1},
  title     = {Exercise-enhanced sequential modeling for student performance prediction},
  volume    = {32},
  year      = {2018}
}

@inproceedings{veli2018graph,
  author    = {Petar Velickovic and
               Guillem Cucurull and
               Arantxa Casanova and
               Adriana Romero and
               Pietro Li{\`{o}} and
               Yoshua Bengio},
  title     = {Graph Attention Networks},
  booktitle = {6th International Conference on Learning Representations, {ICLR} 2018,
               Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings},
  publisher = {OpenReview.net},
  year      = {2018}
}


@article{zhou2018graph,
  author  = {Zhou, Jie and Cui, Ganqu and Zhang, Zhengyan and Yang, Cheng and Liu, Zhiyuan and Wang, Lifeng and Li, Changcheng and Sun, Maosong},
  journal = {arXiv preprint arXiv:1812.08434},
  title   = {Graph neural networks: A review of methods and applications},
  year    = {2018}
}

@article{Novotn2018Cosinemeasure,
  title     = {Implementation Notes for the Soft Cosine Measure},
  isbn      = {9781450360142},
  url       = {http://dx.doi.org/10.1145/3269206.3269317},
  doi       = {10.1145/3269206.3269317},
  journal   = {Proceedings of the 27th ACM International Conference on Information and Knowledge Management},
  publisher = {ACM},
  author    = {Novotný, Vít},
  year      = {2018},
  month     = {Oct}
}


@article{chaudhry2018modeling,
  author    = {Chaudhry, Ritwick and Singh, Harvineet and Dogga, Pradeep and Saini, Shiv Kumar},
  journal   = {International Educational Data Mining Society},
  publisher = {ERIC},
  title     = {Modeling Hint-Taking Behavior and Knowledge State of Students with Multi-Task Learning.},
  year      = {2018}
}

@inproceedings{sun2018multi,
  author    = {Sun, Ming and Yuan, Yuchen and Zhou, Feng and Ding, Errui},
  booktitle = {Proceedings of the European Conference on Computer Vision (ECCV)},
  pages     = {805--821},
  title     = {Multi-attention multi-class constraint for fine-grained image recognition},
  year      = {2018}
}

@inproceedings{cui2018performance,
  author       = {Cui, Wei and Xue, Zhen and Thai, Khanh-Phuong},
  booktitle    = {2018 Chinese Automation Congress (CAC)},
  organization = {IEEE},
  pages        = {3170--3175},
  title        = {Performance comparison of an AI-based Adaptive Learning System in China},
  year         = {2018}
}

@article{chen2018recommendation,
  title     = {Recommendation system for adaptive learning},
  author    = {Chen, Yunxiao and Li, Xiaoou and Liu, Jingchen and Ying, Zhiliang},
  journal   = {Applied psychological measurement},
  volume    = {42},
  number    = {1},
  pages     = {24--41},
  year      = {2018},
  publisher = {Sage Publications Sage CA: Los Angeles, CA}
}

@article{wu2018socialgcn,
  author  = {Wu, Le and Sun, Peijie and Hong, Richang and Fu, Yanjie and Wang, Xiting and Wang, Meng},
  journal = {arXiv preprint arXiv:1811.02815},
  title   = {SocialGCN: an efficient graph convolutional network based model for social recommendation},
  year    = {2018}
}
@article{wang2017hybrid,
  title     = {A hybrid user similarity model for collaborative filtering},
  author    = {Wang, Yong and Deng, Jiangzhou and Gao, Jerry and Zhang, Pu},
  journal   = {Information Sciences},
  volume    = {418},
  pages     = {102--118},
  year      = {2017},
  publisher = {Elsevier}
}
@misc{vaswani2017attention,
  archiveprefix = {arXiv},
  author        = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
  eprint        = {1706.03762},
  primaryclass  = {cs.CL},
  title         = {Attention Is All You Need},
  year          = {2017}
}

@inproceedings{joulin-etal-2017-bag,
  title     = {Bag of Tricks for Efficient Text Classification},
  author    = {Joulin, Armand  and
      Grave, Edouard  and
      Bojanowski, Piotr  and
      Mikolov, Tomas},
  booktitle = {Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 2, Short Papers},
  month     = apr,
  year      = {2017},
  address   = {Valencia, Spain},
  publisher = {Association for Computational Linguistics},
  pages     = {427--431}
}

@inproceedings{guo2017deepfm,
  author    = {Guo, Huifeng and Tang, Ruiming and Ye, Yunming and Li, Zhenguo and He, Xiuqiang},
  title     = {DeepFM: A Factorization-Machine Based Neural Network for CTR Prediction},
  year      = {2017},
  isbn      = {9780999241103},
  publisher = {AAAI Press},
  abstract  = {Learning sophisticated feature interactions behind user behaviors is critical in maximizing CTR for recommender systems. Despite great progress, existing methods seem to have a strong bias towards low- or high-order interactions, or require expertise feature engineering. In this paper, we show that it is possible to derive an end-to-end learning model that emphasizes both low- and high-order feature interactions. The proposed model, DeepFM, combines the power of factorization machines for recommendation and deep learning for feature learning in a new neural network architecture. Compared to the latest Wide & Deep model from Google, DeepFM has a shared input to its "wide" and "deep" parts, with no need of feature engineering besides raw features. Comprehensive experiments are conducted to demonstrate the effectiveness and efficiency of DeepFM over the existing models for CTR prediction, on both benchmark data and commercial data.},
  booktitle = {Proceedings of the 26th International Joint Conference on Artificial Intelligence},
  pages     = {1725–1731},
  numpages  = {7},
  location  = {Melbourne, Australia},
  series    = {IJCAI'17}
}


@inproceedings{zhang2017dynamic,
  author    = {Zhang, Jiani and Shi, Xingjian and King, Irwin and Yeung, Dit-Yan},
  booktitle = {Proceedings of the 26th international conference on World Wide Web},
  pages     = {765--774},
  title     = {Dynamic key-value memory networks for knowledge tracing},
  year      = {2017}
}

@inproceedings{leeJ2020accardcf,
  author = {Lee, Soojung},
  doi    = {10.1007/978-981-10-4154-9_93},
  isbn   = {978-981-10-4153-2},
  month  = {03},
  pages  = {799-806},
  title  = {Improving Jaccard Index for Measuring Similarity in Collaborative Filtering},
  year   = {2017}
}
@article{hamilton2017inductive,
  author  = {Hamilton, William L and Ying, Rex and Leskovec, Jure},
  journal = {arXiv preprint arXiv:1706.02216},
  title   = {Inductive representation learning on large graphs},
  year    = {2017}
}

@article{wang2017knowledge,
  author    = {Wang, Quan and Mao, Zhendong and Wang, Bin and Guo, Li},
  journal   = {IEEE Transactions on Knowledge and Data Engineering},
  number    = {12},
  pages     = {2724--2743},
  publisher = {IEEE},
  title     = {Knowledge graph embedding: A survey of approaches and applications},
  volume    = {29},
  year      = {2017}
}

@article{he2017learning,
  author  = {He, He and Balakrishnan, Anusha and Eric, Mihail and Liang, Percy},
  journal = {arXiv preprint arXiv:1704.07130},
  title   = {Learning symmetric collaborative dialogue agents with dynamic knowledge graph embeddings},
  year    = {2017}
}

@inproceedings{fu2017look,
  author    = {Fu, Jianlong and Zheng, Heliang and Mei, Tao},
  booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages     = {4438--4446},
  title     = {Look closer to see better: Recurrent attention convolutional neural network for fine-grained image recognition},
  year      = {2017}
}


@article{huang2017hcdm,
  author   = {Huang, Hung-Yu},
  title    = {Multilevel Cognitive Diagnosis Models for Assessing Changes in Latent Attributes},
  journal  = {Journal of Educational Measurement},
  volume   = {54},
  number   = {4},
  pages    = {440-480},
  doi      = {https://doi.org/10.1111/jedm.12156},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1111/jedm.12156},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/jedm.12156},
  abstract = {Abstract Cognitive diagnosis models (CDMs) have been developed to evaluate the mastery status of individuals with respect to a set of defined attributes or skills that are measured through testing. When individuals are repeatedly administered a cognitive diagnosis test, a new class of multilevel CDMs is required to assess the changes in their attributes and simultaneously estimate the model parameters from the different measurements. In this study, the most general CDM of the generalized deterministic input, noisy “and” gate (G-DINA) model was extended to a multilevel higher order CDM by embedding a multilevel structure into higher order latent traits. A series of simulations based on diverse factors was conducted to assess the quality of the parameter estimation. The results demonstrate that the model parameters can be recovered fairly well and attribute mastery can be precisely estimated if the sample size is large and the test is sufficiently long. The range of the location parameters had opposing effects on the recovery of the item and person parameters. Ignoring the multilevel structure in the data by fitting a single-level G-DINA model decreased the attribute classification accuracy and the precision of latent trait estimation. The number of measurement occasions had a substantial impact on latent trait estimation. Satisfactory model and person parameter recoveries could be achieved even when assumptions of the measurement invariance of the model parameters over time were violated. A longitudinal basic ability assessment is outlined to demonstrate the application of the new models.},
  year     = {2017}
}

@inproceedings{kipf2017semi,
  author    = {Thomas N. Kipf and
               Max Welling},
  title     = {Semi-Supervised Classification with Graph Convolutional Networks},
  booktitle = {5th International Conference on Learning Representations, {ICLR} 2017,
               Toulon, France, April 24-26, 2017, Conference Track Proceedings},
  publisher = {OpenReview.net},
  year      = {2017}
}


@article{tanujaya2017relationship,
  author    = {Tanujaya, Benidiktus and Mumu, Jeinne and Margono, Gaguk},
  journal   = {International Education Studies},
  number    = {11},
  pages     = {78--85},
  publisher = {ERIC},
  title     = {The Relationship between Higher Order Thinking Skills and Academic Performance of Student in Mathematics Instruction.},
  volume    = {10},
  year      = {2017}
}

@article{church2017word2vec,
  title     = {Word2Vec},
  author    = {Church, Kenneth Ward},
  journal   = {Natural Language Engineering},
  volume    = {23},
  number    = {1},
  pages     = {155--162},
  year      = {2017},
  publisher = {Cambridge University Press}
}

@article{ma2017adalearn,
  author  = {马相春 and 钟绍春 and 徐妲},
  journal = {中国电化教育},
  pages   = {97--102},
  title   = {大数据视角下个性化自适应学习系统支撑模型及实现机制研究},
  volume  = {4},
  year    = {2017}
}

@inproceedings{zhou2016attention,
  author    = {Zhou, Peng and Shi, Wei and Tian, Jun and Qi, Zhenyu and Li, Bingchen and Hao, Hongwei and Xu, Bo},
  booktitle = {Proceedings of the 54th annual meeting of the association for computational linguistics (volume 2: Short papers)},
  pages     = {207--212},
  title     = {Attention-based bidirectional long short-term memory networks for relation classification},
  year      = {2016}
}

@inproceedings{wang2016cnn,
  author    = {Wang, Jiang and Yang, Yi and Mao, Junhua and Huang, Zhiheng and Huang, Chang and Xu, Wei},
  booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages     = {2285--2294},
  title     = {Cnn-rnn: A unified framework for multi-label image classification},
  year      = {2016}
}

@inproceedings{shan2016deep,
  author    = {Shan, Ying and Hoens, T Ryan and Jiao, Jian and Wang, Haijing and Yu, Dong and Mao, JC},
  booktitle = {Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining},
  pages     = {255--262},
  title     = {Deep crossing: Web-scale modeling without manually crafted combinatorial features},
  year      = {2016}
}

@inproceedings{day2016deep,
  author       = {Day, Min-Yuh and Lee, Chia-Chou},
  booktitle    = {2016 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)},
  organization = {IEEE},
  pages        = {1127--1134},
  title        = {Deep learning for financial sentiment analysis on finance news providers},
  year         = {2016}
}

@inproceedings{he2016deep,
  title     = {Deep residual learning for image recognition},
  author    = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages     = {770--778},
  year      = {2016}
}


@inproceedings{juan2016field,
  author    = {Juan, Yuchin and Zhuang, Yong and Chin, Wei-Sheng and Lin, Chih-Jen},
  booktitle = {Proceedings of the 10th ACM Conference on Recommender Systems},
  pages     = {43--50},
  title     = {Field-aware factorization machines for CTR prediction},
  year      = {2016}
}
@article{ba2016layer,
  title   = {Layer normalization},
  author  = {Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E},
  journal = {arXiv preprint arXiv:1607.06450},
  year    = {2016}
}

@inproceedings{santoro2016meta,
  author       = {Santoro, Adam and Bartunov, Sergey and Botvinick, Matthew and Wierstra, Daan and Lillicrap, Timothy},
  booktitle    = {International conference on machine learning},
  organization = {PMLR},
  pages        = {1842--1850},
  title        = {Meta-learning with memory-augmented neural networks},
  year         = {2016}
}
@inproceedings{cheng2016wide,
  author    = {Cheng, Heng-Tze and Koc, Levent and Harmsen, Jeremiah and Shaked, Tal and Chandra, Tushar and Aradhye, Hrishi and Anderson, Glen and Corrado, Greg and Chai, Wei and Ispir, Mustafa and others},
  booktitle = {Proceedings of the 1st workshop on deep learning for recommender systems},
  pages     = {7--10},
  title     = {Wide \& deep learning for recommender systems},
  year      = {2016}
}

@misc{assistmentdata2015,
  author       = {Neil Heffernan},
  title        = {2015 ASSISTments Skill Builder Data},
  howpublished = {\url{https://sites.google.com/site/assistmentsdata/home/2015-assistments-skill-builder-data}},
  year         = 2015
}


@article{chorowski2015attention,
  author  = {Chorowski, Jan and Bahdanau, Dzmitry and Serdyuk, Dmitriy and Cho, Kyunghyun and Bengio, Yoshua},
  journal = {arXiv preprint arXiv:1506.07503},
  title   = {Attention-based models for speech recognition},
  year    = {2015}
}


@article{piech2015deep,
  author  = {Piech, Chris and Bassen, Jonathan and Huang, Jonathan and Ganguli, Surya and Sahami, Mehran and Guibas, Leonidas J and Sohl-Dickstein, Jascha},
  journal = {Advances in neural information processing systems},
  pages   = {505--513},
  title   = {Deep knowledge tracing},
  volume  = {28},
  year    = {2015}
}

@inproceeding{bahdanau2014neural,
  title     = {Neural machine translation by jointly learning to align and translate},
  abstract  = {Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder–decoders and encode a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder–decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.},
  author    = {Dzmitry Bahdanau and Cho, {Kyung Hyun} and Yoshua Bengio},
  year      = {2015},
  month     = July,
  day       = {05},
  booktitle = {3rd International Conference on Learning Representations, ICLR 2015}
}

@inproceedings{gopalan2014content,
  author    = {Gopalan, Prem and Charlin, Laurent and Blei, David M and others},
  booktitle = {NIPS},
  pages     = {3176--3184},
  title     = {Content-based recommendations with Poisson factorization.},
  volume    = {14},
  year      = {2014}
}

@inproceedings{kim-2014-convolutional,
  title     = {Convolutional Neural Networks for Sentence Classification},
  author    = {Kim, Yoon},
  booktitle = {Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})},
  month     = oct,
  year      = {2014},
  address   = {Doha, Qatar},
  publisher = {Association for Computational Linguistics},
  url       = {https://www.aclweb.org/anthology/D14-1181},
  doi       = {10.3115/v1/D14-1181},
  pages     = {1746--1751}
}

@inproceedings{gonzalez2014general,
  title        = {General features in knowledge tracing to model multiple subskills, temporal item response theory, and expert knowledge},
  author       = {Gonz{\'a}lez-Brenes, Jos{\'e} and Huang, Yun and Brusilovsky, Peter},
  booktitle    = {The 7th international conference on educational data mining},
  pages        = {84--91},
  year         = {2014},
  organization = {University of Pittsburgh}
}

@article{rong2014word2vec,
  author  = {Rong, Xin},
  journal = {arXiv preprint arXiv:1411.2738},
  title   = {word2vec parameter learning explained},
  year    = {2014}
}

@misc{assistmentdata2012,
  author       = {Neil Heffernan},
  title        = {2012-13 School Data with Affect},
  howpublished = {\url{https://sites.google.com/site/assistmentsdata/home/2012-13-school-data-with-affect}},
  year         = 2013
}
@article{zhang2013review,
  author    = {Zhang, Min-Ling and Zhou, Zhi-Hua},
  journal   = {IEEE transactions on knowledge and data engineering},
  number    = {8},
  pages     = {1819--1837},
  publisher = {IEEE},
  title     = {A review on multi-label learning algorithms},
  volume    = {26},
  year      = {2013}
}

@article{mikolov2013distributed,
  author  = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  journal = {arXiv preprint arXiv:1310.4546},
  title   = {Distributed representations of words and phrases and their compositionality},
  year    = {2013}
}

@misc{mikolov2013efficient,
  archiveprefix = {arXiv},
  author        = {Tomas Mikolov and Kai Chen and Greg Corrado and Jeffrey Dean},
  eprint        = {1301.3781},
  primaryclass  = {cs.CL},
  title         = {Efficient Estimation of Word Representations in Vector Space},
  year          = {2013}
}

@inproceedings{yudelson2013individualized,
  author       = {Yudelson, Michael V and Koedinger, Kenneth R and Gordon, Geoffrey J},
  booktitle    = {International conference on artificial intelligence in education},
  organization = {Springer},
  pages        = {171--180},
  title        = {Individualized bayesian knowledge tracing models},
  year         = {2013}
}

@book{embretson2013item,
  author    = {Embretson, Susan E and Reise, Steven P},
  publisher = {Psychology Press},
  title     = {Item response theory},
  year      = {2013}
}

@inproceedings{maas2013rectifier,
  title        = {Rectifier nonlinearities improve neural network acoustic models},
  author       = {Maas, Andrew L and Hannun, Awni Y and Ng, Andrew Y},
  booktitle    = {Proc. icml},
  volume       = {30},
  number       = {1},
  pages        = {3},
  year         = {2013},
  organization = {Citeseer}
}

@article{rendle2012bpr,
  author  = {Rendle, Steffen and Freudenthaler, Christoph and Gantner, Zeno and Schmidt-Thieme, Lars},
  journal = {arXiv preprint arXiv:1205.2618},
  title   = {BPR: Bayesian personalized ranking from implicit feedback},
  year    = {2012}
}

@inproceedings{mikolov2011extensions,
  author       = {Mikolov, Tom{\'a}{\v{s}} and Kombrink, Stefan and Burget, Luk{\'a}{\v{s}} and {\v{C}}ernock{\`y}, Jan and Khudanpur, Sanjeev},
  booktitle    = {2011 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  organization = {IEEE},
  pages        = {5528--5531},
  title        = {Extensions of recurrent neural network language model},
  year         = {2011}
}

@misc{assistmentdata2009,
  author       = {Neil Heffernan},
  title        = {2009-2010 ASSISTment Data},
  howpublished = {\url{https://sites.google.com/site/assistmentsdata/home/assistment-2009-2010-data}},
  year         = 2010
}


@inproceedings{rendle2010factorization,
  author       = {Rendle, Steffen},
  booktitle    = {2010 IEEE International Conference on Data Mining},
  organization = {IEEE},
  pages        = {995--1000},
  title        = {Factorization machines},
  year         = {2010}
}

@article{su2009survey,
  author    = {Su, Xiaoyuan and Khoshgoftaar, Taghi M},
  journal   = {Advances in artificial intelligence},
  publisher = {Hindawi},
  title     = {A survey of collaborative filtering techniques},
  volume    = {2009},
  year      = {2009}
}



@article{de2009dina,
  author    = {De La Torre, Jimmy},
  journal   = {Journal of educational and behavioral statistics},
  number    = {1},
  pages     = {115--130},
  publisher = {Sage Publications Sage CA: Los Angeles, CA},
  title     = {DINA model and parameter estimation: A didactic},
  volume    = {34},
  year      = {2009}
}


@inproceedings{hu2008collaborative,
  author       = {Hu, Yifan and Koren, Yehuda and Volinsky, Chris},
  booktitle    = {2008 Eighth IEEE International Conference on Data Mining},
  organization = {Ieee},
  pages        = {263--272},
  title        = {Collaborative filtering for implicit feedback datasets},
  year         = {2008}
}


@inproceedings{tan2008learning,
  author       = {Tan, Huiyi and Guo, Junfei and Li, Yong},
  booktitle    = {2008 International Conference on Computer Science and Software Engineering},
  organization = {IEEE},
  pages        = {430--433},
  title        = {E-learning recommendation system},
  volume       = {5},
  year         = {2008}
}


@inproceedings{koren2008factorization,
  author    = {Koren, Yehuda},
  booktitle = {Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages     = {426--434},
  title     = {Factorization meets the neighborhood: a multifaceted collaborative filtering model},
  year      = {2008}
}
@article{scarselli2008graph,
  author    = {Scarselli, Franco and Gori, Marco and Tsoi, Ah Chung and Hagenbuchner, Markus and Monfardini, Gabriele},
  journal   = {IEEE transactions on neural networks},
  number    = {1},
  pages     = {61--80},
  publisher = {IEEE},
  title     = {The graph neural network model},
  volume    = {20},
  year      = {2008}
}


@article{zhang2007ml,
  author    = {Zhang, Min-Ling and Zhou, Zhi-Hua},
  journal   = {Pattern recognition},
  number    = {7},
  pages     = {2038--2048},
  publisher = {Elsevier},
  title     = {ML-KNN: A lazy learning approach to multi-label learning},
  volume    = {40},
  year      = {2007}
}


@article{tsoumakas2007multi,
  author    = {Tsoumakas, Grigorios and Katakis, Ioannis},
  journal   = {International Journal of Data Warehousing and Mining (IJDWM)},
  number    = {3},
  pages     = {1--13},
  publisher = {IGI Global},
  title     = {Multi-label classification: An overview},
  volume    = {3},
  year      = {2007}
}

@inproceedings{salakhutdinov2007restricted,
  author    = {Salakhutdinov, Ruslan and Mnih, Andriy and Hinton, Geoffrey},
  booktitle = {Proceedings of the 24th international conference on Machine learning},
  pages     = {791--798},
  title     = {Restricted Boltzmann machines for collaborative filtering},
  year      = {2007}
}

@inproceedings{wang2006unifying,
  author    = {Wang, Jun and De Vries, Arjen P and Reinders, Marcel JT},
  booktitle = {Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval},
  pages     = {501--508},
  title     = {Unifying user-based and item-based collaborative filtering approaches by similarity fusion},
  year      = {2006}
}

@article{graves2005framewise,
  title     = {Framewise phoneme classification with bidirectional LSTM and other neural network architectures},
  author    = {Graves, Alex and Schmidhuber, J{\"u}rgen},
  journal   = {Neural networks},
  volume    = {18},
  number    = {5-6},
  pages     = {602--610},
  year      = {2005},
  publisher = {Elsevier}
}

@inproceedings{mclaughlin2004collaborative,
  author    = {McLaughlin, Matthew R and Herlocker, Jonathan L},
  booktitle = {Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval},
  pages     = {329--336},
  title     = {A collaborative filtering algorithm and evaluation metric that accurately model the user experience},
  year      = {2004}
}

@article{bengio2003neural,
  author    = {Bengio, Yoshua and Ducharme, R{\'e}jean and Vincent, Pascal and Janvin, Christian},
  journal   = {The journal of machine learning research},
  pages     = {1137--1155},
  publisher = {JMLR. org},
  title     = {A neural probabilistic language model},
  volume    = {3},
  year      = {2003}
}

@article{brusilovsky2001adaptive,
  author    = {Brusilovsky, Peter},
  journal   = {User modeling and user-adapted interaction},
  number    = {1},
  pages     = {87--110},
  publisher = {Springer},
  title     = {Adaptive hypermedia},
  volume    = {11},
  year      = {2001}
}

@article{lstm1997,
  author  = {Hochreiter, Sepp and Schmidhuber, Jürgen},
  doi     = {10.1162/neco.1997.9.8.1735},
  journal = {Neural computation},
  month   = {12},
  pages   = {1735-80},
  title   = {Long Short-term Memory},
  volume  = {9},
  year    = {1997}
}
