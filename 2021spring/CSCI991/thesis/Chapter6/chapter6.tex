\chapter{Conclusion and Future Work}

%在本文中，设计了一个基于图神经网络、Attention-based Bi-LSTM、Transformer以及协同过滤等算法的习题推荐系统。该系统分为三个模块，分别为习题知识点挖掘模块、知识追踪模块和习题推荐模块。习题知识点挖掘模块可以未标注知识点的习题进行知识点标注，并将标注知识点的习题作为知识追踪的输入数据。知识追踪模块追踪学生的做题记录，从而跟踪学生的知识状态。习题推荐模块则结合学生的知识状态和习题标签信息，进行针对性的习题推荐。

%在未来的工作中，可以结合其他的图神经网络模型或者加入一些记忆力机制来解决模型的序列性问题。
In this article, an exercise recommendation system based on graph neural network, Attention-based Bi-LSTM, Transformer and collaborative filtering algorithms is designed. The system is divided into three modules, namely exercise knowledge point mining module, knowledge tracking module and exercise recommendation module. The exercise knowledge point mining module can mark the knowledge points of the exercises without the knowledge points, and use the exercises with the marked knowledge points as the input data for knowledge tracking. The knowledge tracking module tracks the students' question records, thereby tracking the students' knowledge status. The exercise recommendation module combines students' knowledge status and exercise label information to make targeted exercise recommendation..

%在知识点标注模块中，采用了图卷积神经网络来训练标签标注分类器。通过Bi-LSTM来挖掘习题文本信息，将习题文本嵌入作为标签分类器组的输入，输出一组标签的分类结果。经过实验验证，该模型对于高中数学习题具有良好的分类效果，对于现有的模型性能上有一定提升。在未来的工作中，可以考虑用Transformer来取代Bi-LSTM模型或者用BERT来训练习题文本嵌入来达到更精确的分类效果。

In the knowledge point annotation module, a graph convolutional neural network is used to train the label annotation classifier. Use Bi-LSTM to mine the exercise text information, embed the exercise text as the input of the label classifier group, and output a set of label classification results. Experiments show that the model has a good classification effect for high school math learning questions, and has a certain improvement in the performance of existing models. In future work, we can consider using Transformer to replace Bi-LSTM model or BERT to train exercise text embedding to achieve more accurate classification results.

%在知识追踪模块中，采用了图注意力网络来进行习题知识关系嵌入学习，将嵌入向量通过基于Transformer的Encoder模型来输出一个知识状态向量，再将习题嵌入向量与知识状态向量作为基于Transformer的Decoder模型的输入，输出对于下一道习题的答题情况预测。经过实验验证，该模型对于知识关系简单与知识关系复杂的数据集都具有较好的预测性能。后续可以考虑采用不同的图神经网络模型来增加学习效率，或者采用更多的习题信息来学习习题知识嵌入。

In the knowledge tracking module, a graph attention network is used to learn the knowledge relationship of exercises. The embedding vector is output through the Transformer-based Encoder model to output a knowledge state vector, and then the exercise embedding vector and the knowledge state vector are used as the Transformer-based Decoder The input and output of the model predict the answer to the next exercise. After experimental verification, the model has good predictive performance for data sets with simple and complex knowledge relationships. Later, you can consider using different graph neural network models to increase learning efficiency, or use more exercise information to learn exercise knowledge embedding.

%在习题推荐模块中，采用了基于协同过滤的召回模型与基于MLP的排序模型。召回阶段通过协同过滤找到知识状态相似的其他学生的习题集合，在排序阶段，将知识追踪模块上获取的知识状态向量与习题的标签向量输入到最终的排序模型，输入一个习题推荐优先级序列。在未来的研究中，可以考虑采用更复杂的排序模型例如集成学习模型，来提高推荐系统性能。

In the exercise recommendation module, a collaborative filtering-based recall model and an MLP-based ranking model are used. The recall phase finds the set of exercises of other students with similar knowledge states by collaborative filtering, and in the ranking phase, the knowledge state vector obtained on the knowledge tracking module and the label vector of the exercises are input to the final ranking model to input an exercise recommendation priority sequence. In future research, more sophisticated ranking models such as integrated learning models can be considered to improve the performance of recommendation systems.